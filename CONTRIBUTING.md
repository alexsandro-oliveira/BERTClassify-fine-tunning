# ğŸ¤ Guia de ContribuiÃ§Ã£o

Obrigado por considerar contribuir para este projeto! Este documento fornece diretrizes para contribuir de forma efetiva.

## ğŸ“‹ CÃ³digo de Conduta

Este projeto adere a um cÃ³digo de conduta. Ao participar, vocÃª concorda em manter um ambiente respeitoso e colaborativo.

## ğŸš€ Como Contribuir

### Reportar Bugs

Ao reportar um bug, inclua:

- **DescriÃ§Ã£o clara** do problema
- **Passos para reproduzir**
- **Comportamento esperado** vs **comportamento atual**
- **Ambiente**: OS, Python version, dependÃªncias
- **Logs/Screenshots** se aplicÃ¡vel

**Template:**

```markdown
## DescriÃ§Ã£o

[DescriÃ§Ã£o clara e concisa do bug]

## ReproduÃ§Ã£o

1. Executar '...'
2. Usar input '...'
3. Observar erro '...'

## Comportamento Esperado

[O que deveria acontecer]

## Ambiente

- OS: [e.g., Windows 11]
- Python: [e.g., 3.9]
- Transformers: [e.g., 4.35.0]

## Logs
```

[cole os logs aqui]

```

```

### Sugerir Melhorias

Para sugestÃµes de features:

- **Use caso claro**
- **BenefÃ­cios esperados**
- **ImplementaÃ§Ã£o proposta** (se tiver ideia)
- **Alternativas consideradas**

### Pull Requests

1. **Fork** o repositÃ³rio
2. **Crie uma branch** para sua feature:
   ```bash
   git checkout -b feature/MinhaFeature
   ```
3. **FaÃ§a commits** descritivos:
   ```bash
   git commit -m "feat: adiciona suporte para multi-label classification"
   ```
4. **Adicione testes** se aplicÃ¡vel
5. **Atualize documentaÃ§Ã£o**
6. **Push** para sua branch:
   ```bash
   git push origin feature/MinhaFeature
   ```
7. **Abra um Pull Request**

## ğŸ“ ConvenÃ§Ãµes de CÃ³digo

### Python Style Guide

Seguimos [PEP 8](https://pep8.org/):

```python
# âœ… Bom
def tokenize_function(example: dict) -> dict:
    """
    Tokeniza o texto de entrada.

    Args:
        example: DicionÃ¡rio com campo 'prompt'

    Returns:
        dict: Tokens e attention masks
    """
    return tokenizer(
        example["prompt"],
        truncation=True,
        padding=True
    )

# âŒ Ruim
def tokenize(ex):
    return tokenizer(ex["prompt"],truncation=True,padding=True)
```

### Commits

Seguimos [Conventional Commits](https://www.conventionalcommits.org/):

```
feat: adiciona nova feature
fix: corrige bug especÃ­fico
docs: atualiza documentaÃ§Ã£o
style: formataÃ§Ã£o de cÃ³digo
refactor: refatoraÃ§Ã£o sem mudanÃ§a de funcionalidade
test: adiciona ou modifica testes
chore: tarefas de manutenÃ§Ã£o
```

**Exemplos:**

```bash
git commit -m "feat: adiciona suporte para 3+ classes"
git commit -m "fix: corrige erro de encoding em textos especiais"
git commit -m "docs: atualiza README com exemplos de uso"
```

### Docstrings

Use docstrings no estilo Google:

```python
def predict(text: str, threshold: float = 0.5) -> dict:
    """
    Realiza prediÃ§Ã£o em um texto.

    Args:
        text: Texto de entrada para classificaÃ§Ã£o
        threshold: Limite mÃ­nimo de confianÃ§a (0-1)

    Returns:
        dict: ContÃ©m 'class', 'confidence' e 'is_certain'

    Raises:
        ValueError: Se text estiver vazio

    Example:
        >>> predict("Preciso de ajuda")
        {'class': 'suporte', 'confidence': 0.95, 'is_certain': True}
    """
    if not text:
        raise ValueError("Text cannot be empty")

    result = classifier(text)[0]
    return {
        'class': result['label'],
        'confidence': result['score'],
        'is_certain': result['score'] >= threshold
    }
```

## ğŸ§ª Testes

### Executar Testes

```bash
# Todos os testes
pytest

# Com cobertura
pytest --cov=. --cov-report=html

# EspecÃ­fico
pytest tests/test_inference.py
```

### Escrever Testes

```python
import pytest
from inference import predict

def test_predict_suporte():
    """Testa classificaÃ§Ã£o de mensagem de suporte."""
    result = predict("Meu produto veio com defeito")
    assert result['class'] == 'suporte'
    assert result['confidence'] > 0.5

def test_predict_empty_text():
    """Testa erro com texto vazio."""
    with pytest.raises(ValueError):
        predict("")

@pytest.mark.parametrize("text,expected", [
    ("Quero comprar", "venda"),
    ("Como configurar?", "suporte"),
])
def test_predict_multiple(text, expected):
    """Testa mÃºltiplos casos."""
    result = predict(text)
    assert result['class'] == expected
```

## ğŸ“ Estrutura de CÃ³digo

Organize contribuiÃ§Ãµes assim:

```
project/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”‚   â””â”€â”€ augmentation.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ bert_classifier.py
â”‚   â”‚   â””â”€â”€ trainer.py
â”‚   â”œâ”€â”€ inference/
â”‚   â”‚   â””â”€â”€ predictor.py
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ helpers.py
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_data.py
â”‚   â”œâ”€â”€ test_models.py
â”‚   â””â”€â”€ test_inference.py
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ fine_tunning_bart.ipynb
â””â”€â”€ docs/
    â”œâ”€â”€ README.md
    â””â”€â”€ DOCUMENTATION.md
```

## ğŸ” Code Review

Ao revisar PRs, verificamos:

- [ ] **Funcionalidade**: CÃ³digo faz o que propÃµe?
- [ ] **Testes**: Tem testes adequados?
- [ ] **DocumentaÃ§Ã£o**: CÃ³digo e docs atualizados?
- [ ] **Style**: Segue convenÃ§Ãµes do projeto?
- [ ] **Performance**: NÃ£o degrada performance?
- [ ] **SeguranÃ§a**: NÃ£o introduz vulnerabilidades?

## ğŸ“Š Contribuindo com Dados

### Adicionar Dados de Treinamento

```json
// Formato correto
{"prompt": "Texto da mensagem do cliente", "completion": "suporte"}
{"prompt": "Outro exemplo de mensagem", "completion": "venda"}
```

**Diretrizes:**

- Textos reais e variados
- Balanceamento entre classes
- Sem informaÃ§Ãµes sensÃ­veis (PII)
- Validar qualidade antes de commit

### Data Quality Checklist

- [ ] Dados anonimizados
- [ ] Labels corretos
- [ ] Textos limpos (sem HTML, etc)
- [ ] DistribuiÃ§Ã£o balanceada
- [ ] Arquivo no formato JSONL

## ğŸ› Debugging

### Habilitar Logs Detalhados

```python
import logging

logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
```

### Profiling

```python
import cProfile
import pstats

profiler = cProfile.Profile()
profiler.enable()

# Seu cÃ³digo aqui
predict("texto de teste")

profiler.disable()
stats = pstats.Stats(profiler)
stats.sort_stats('cumulative')
stats.print_stats(10)
```

## ğŸ“š Recursos

### Aprender Mais

- [Transformers Course](https://huggingface.co/course)
- [PyTorch Tutorials](https://pytorch.org/tutorials/)
- [BERT Paper](https://arxiv.org/abs/1810.04805)

### Ferramentas Ãšteis

- **Linting**: `flake8`, `pylint`
- **Formatting**: `black`, `isort`
- **Type Checking**: `mypy`
- **Testing**: `pytest`, `pytest-cov`

## â“ DÃºvidas?

- Abra uma [Discussion](https://github.com/seu-usuario/seu-repo/discussions)
- Entre em contato: seu-email@example.com

## ğŸ‰ Reconhecimento

Contribuidores serÃ£o listados no README e em releases notes!

---

**Obrigado por contribuir! ğŸš€**
