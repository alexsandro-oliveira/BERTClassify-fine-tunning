# ğŸ¤– BERT Text Classifier - Suporte vs Vendas

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Transformers](https://img.shields.io/badge/ğŸ¤—-Transformers-yellow.svg)](https://huggingface.co/transformers/)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)

## ğŸ“‹ DescriÃ§Ã£o

Modelo de classificaÃ§Ã£o de texto baseado em BERT para categorizar automaticamente mensagens de clientes entre **Suporte** e **Vendas**. Ãštil para sistemas de triagem automÃ¡tica, chatbots e anÃ¡lise de tickets.

### ğŸ¯ Casos de Uso

- Roteamento automÃ¡tico de tickets de atendimento
- ClassificaÃ§Ã£o de e-mails corporativos
- Triagem de mensagens em chatbots
- AnÃ¡lise de intenÃ§Ã£o do cliente

## ğŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Texto de Input â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BERT Tokenizer â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   BERT Model    â”‚
â”‚ (bert-base-     â”‚
â”‚  uncased)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Classification  â”‚
â”‚ Head (2 labels) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Suporte | Venda â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### PrÃ©-requisitos

- Python 3.8 ou superior
- GPU com CUDA (recomendado) ou CPU
- 4GB+ RAM

### InstalaÃ§Ã£o

1. Clone o repositÃ³rio:

```bash
git clone <seu-repositorio>
cd fine_tunning/models
```

2. Instale as dependÃªncias:

```bash
pip install -r requirements.txt
```

3. (Opcional) Configure o Hugging Face:

```bash
huggingface-cli login
```

## ğŸ“Š Dataset

### Formato dos Dados

Os dados devem estar no formato JSONL com a seguinte estrutura:

```json
{"prompt": "Como faÃ§o para configurar o fogÃ£o elÃ©trico?", "completion": "suporte"}
{"prompt": "Quero comprar um micro-ondas, vocÃªs tÃªm sugestÃµes?", "completion": "venda"}
```

### Estrutura de Arquivos

```
â”œâ”€â”€ train.jsonl          # Dados de treinamento
â”œâ”€â”€ test.jsonl           # Dados de validaÃ§Ã£o
â””â”€â”€ data/                # (Opcional) Dados adicionais
```

### Classes

| Classe  | Label | DescriÃ§Ã£o                             |
| ------- | ----- | ------------------------------------- |
| suporte | 0     | QuestÃµes tÃ©cnicas, problemas, ajuda   |
| venda   | 1     | Interesse em compra, preÃ§os, produtos |

## ğŸ› ï¸ Treinamento

### Usando o Notebook

Execute as cÃ©lulas do notebook `fine_tunning_bart.ipynb` sequencialmente:

1. **AutenticaÃ§Ã£o** (se necessÃ¡rio)
2. **Carregamento dos dados**
3. **TokenizaÃ§Ã£o**
4. **ConfiguraÃ§Ã£o do treinamento**
5. **Treinamento do modelo**
6. **AvaliaÃ§Ã£o**
7. **Salvamento**

### HiperparÃ¢metros

```python
num_train_epochs = 3
per_device_train_batch_size = 8
learning_rate = 5e-5
weight_decay = 0.01
warmup_steps = 100
```

### MÃ©tricas de AvaliaÃ§Ã£o

- **Accuracy**: MÃ©trica principal
- **Loss**: Monitoramento do treinamento
- AvaliaÃ§Ã£o a cada 200 steps

## ğŸ’» Uso

### InferÃªncia BÃ¡sica

```python
from transformers import pipeline

# Carregar modelo
classifier = pipeline("text-classification",
                     model="./bert-validator-test")

# Fazer prediÃ§Ã£o
texto = "Preciso de ajuda com meu pedido"
resultado = classifier(texto)
print(resultado)
# [{'label': 'LABEL_0', 'score': 0.95}]  # suporte
```

### InferÃªncia com Labels Customizados

```python
label_names = {0: "suporte", 1: "venda"}

def classificar_texto(texto):
    resultado = classifier(texto)[0]
    label_id = int(resultado['label'].split('_')[-1])
    classe = label_names[label_id]
    confianca = resultado['score']

    return {
        'classe': classe,
        'confianca': confianca
    }

# Exemplo
resultado = classificar_texto("Quanto custa o produto X?")
print(f"Classe: {resultado['classe']}")
print(f"ConfianÃ§a: {resultado['confianca']:.2%}")
```

### Batch Prediction

```python
textos = [
    "Meu produto veio com defeito",
    "Gostaria de comprar 5 unidades",
    "Como faÃ§o para resetar a senha?"
]

resultados = classifier(textos)
for texto, resultado in zip(textos, resultados):
    print(f"{texto} â†’ {resultado['label']}")
```

## ğŸ“ Estrutura do Projeto

```
fine_tunning/models/
â”‚
â”œâ”€â”€ fine_tunning_bart.ipynb    # Notebook principal
â”œâ”€â”€ requirements.txt            # DependÃªncias
â”œâ”€â”€ README.md                   # DocumentaÃ§Ã£o
â”œâ”€â”€ DOCUMENTATION.md            # DocumentaÃ§Ã£o tÃ©cnica detalhada
â”‚
â”œâ”€â”€ train.jsonl                 # Dados de treinamento
â”œâ”€â”€ test.jsonl                  # Dados de teste
â”‚
â”œâ”€â”€ bert-validator-test/        # Modelo treinado
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ model.safetensors
â”‚   â”œâ”€â”€ tokenizer.json
â”‚   â”œâ”€â”€ vocab.txt
â”‚   â””â”€â”€ checkpoint-*/           # Checkpoints intermediÃ¡rios
â”‚
â”œâ”€â”€ logs/                       # Logs de treinamento
â””â”€â”€ data/                       # Dados adicionais
```

## ğŸ”§ ConfiguraÃ§Ã£o AvanÃ§ada

### Ajuste de HiperparÃ¢metros

Para melhorar o desempenho, ajuste os parÃ¢metros em `TrainingArguments`:

```python
training_args = TrainingArguments(
    output_dir="./bert-validator-test",
    num_train_epochs=5,              # Mais Ã©pocas
    learning_rate=3e-5,              # LR menor
    per_device_train_batch_size=16,  # Batch maior (se GPU permitir)
    warmup_ratio=0.1,                # 10% warmup
    weight_decay=0.01,
    fp16=True,                       # Mixed precision
)
```

### Data Augmentation

Para datasets pequenos, considere:

```python
from nlpaug.augmenter.word import SynonymAug

aug = SynonymAug(aug_src='wordnet')
augmented_text = aug.augment(original_text)
```

### Early Stopping

```python
from transformers import EarlyStoppingCallback

trainer = Trainer(
    # ... outros parÃ¢metros
    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]
)
```

## ğŸ“ˆ Performance

### Resultados Esperados

Com o dataset padrÃ£o:

- **Accuracy**: ~85-95% (depende do dataset)
- **Training time**: ~10-30 min (GPU) / 1-3h (CPU)
- **Inference**: ~50-100ms por texto (GPU) / 200-500ms (CPU)

### OtimizaÃ§Ã£o de InferÃªncia

Para produÃ§Ã£o, considere:

1. **ONNX Runtime**: 2-3x mais rÃ¡pido
2. **QuantizaÃ§Ã£o**: Modelo menor, inferÃªncia mais rÃ¡pida
3. **Batch processing**: Processar mÃºltiplos textos juntos

## ğŸ› Troubleshooting

### Erro de MemÃ³ria (OOM)

Reduza o batch size:

```python
per_device_train_batch_size = 4  # ou menor
gradient_accumulation_steps = 8  # compensar batch menor
```

### Overfitting

- Aumentar `weight_decay`
- Adicionar dropout
- Usar data augmentation
- Coletar mais dados

### Underfitting

- Aumentar `num_train_epochs`
- Ajustar `learning_rate`
- Verificar qualidade dos dados

## ğŸ¤ Contribuindo

1. Fork o projeto
2. Crie uma branch (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo `LICENSE` para mais detalhes.

## ğŸ‘¥ Autores

- Seu Nome - [GitHub](https://github.com/seu-usuario)

## ğŸ™ Agradecimentos

- [Hugging Face](https://huggingface.co/) pela biblioteca Transformers
- [BERT](https://arxiv.org/abs/1810.04805) - Devlin et al., 2018
- Comunidade open source

## ğŸ“š ReferÃªncias

- [BERT: Pre-training of Deep Bidirectional Transformers](https://arxiv.org/abs/1810.04805)
- [Hugging Face Transformers Documentation](https://huggingface.co/docs/transformers/)
- [Fine-tuning Best Practices](https://huggingface.co/docs/transformers/training)

## ğŸ“ Suporte

Para questÃµes e suporte:

- Abra uma [issue](https://github.com/seu-usuario/seu-repo/issues)
- Email: seu-email@example.com

---

â­ Se este projeto foi Ãºtil, considere dar uma estrela!
